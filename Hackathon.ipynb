{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jgGALXUUIlo"
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be01DsvnUIEW",
        "outputId": "7bc50210-cfa8-4611-c62c-de6b5df17f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GenAI configured successfully.\n",
            "Google Cloud credentials set.\n",
            "Setup complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from google.cloud import vision\n",
        "import cv2\n",
        "\n",
        "import textwrap\n",
        "from inference_sdk import InferenceHTTPClient\n",
        "# Assuming google.generativeai is a valid module and used later in the code\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "import numpy as np\n",
        "\n",
        "# Use environment variables for sensitive information\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY', 'AIzaSyArNvjy-dtSnMvKsqWsR9dBtVQ8eUSdlAg')\n",
        "GOOGLE_APPLICATION_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS', 'ornate-grail-426902-p3-b90b1e5ffe06.json')\n",
        "\n",
        "if GOOGLE_API_KEY is None:\n",
        "    print(\"Error: GOOGLE_API_KEY environment variable not set.\")\n",
        "else:\n",
        "    try:\n",
        "        genai.configure(api_key=GOOGLE_API_KEY)\n",
        "        print(\"GenAI configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring GenAI: {e}\")\n",
        "\n",
        "# Set Google Cloud credentials environment variable\n",
        "if GOOGLE_APPLICATION_CREDENTIALS:\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS\n",
        "    print(\"Google Cloud credentials set.\")\n",
        "else:\n",
        "    print(\"Error: GOOGLE_APPLICATION_CREDENTIALS environment variable not set or invalid.\")\n",
        "\n",
        "print(\"Setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "tawitRjHUgQk"
      },
      "outputs": [],
      "source": [
        "class DrawBoundingBoxes:\n",
        "    def __init__(self, image, results):\n",
        "        self.image = image\n",
        "        self.predictions = results['predictions']\n",
        "        self.draw = ImageDraw.Draw(self.image)\n",
        "\n",
        "    def draw_bbox_with_polygon(self):\n",
        "        \"\"\"Draws bounding boxes as polygons based on the predictions.\"\"\"\n",
        "        for pred in self.predictions:\n",
        "            vertices = pred['vertices']\n",
        "            label = pred['label']\n",
        "            # Draw the polygon based on vertices\n",
        "            self.draw.polygon(vertices, outline=\"red\", width=4)\n",
        "            # Position for the label is slightly above and to the right of the first vertex\n",
        "            label_pos = (vertices[0][0] + 10, vertices[0][1] - 10)\n",
        "            self.draw.text(label_pos, label, fill=\"red\")\n",
        "\n",
        "    def show_image_with_bbox(self):\n",
        "        \"\"\"Displays the image with bounding boxes.\"\"\"\n",
        "        self.draw_bbox_with_polygon()\n",
        "        plt.imshow(self.image)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    def save_image_with_bbox(self, output_image_path):\n",
        "        \"\"\"Saves the image with bounding boxes to the specified path.\"\"\"\n",
        "        self.draw_bbox_with_polygon()\n",
        "        self.image.save(output_image_path)\n",
        "        print(f\"Image saved to {output_image_path}\")\n",
        "\n",
        "\n",
        "def convert_to_polygon(bounds):\n",
        "    \"\"\"Converts bounding box coordinates to a polygon (list of tuples).\"\"\"\n",
        "    # return [(bounds['xmin']-5, bounds['ymin']-5),\n",
        "    #         (bounds['xmax'], bounds['ymin']),\n",
        "    #         (bounds['xmax'], bounds['ymax']),\n",
        "    #         (bounds['xmin'], bounds['ymax'])]\n",
        "    return [(bounds['xmin'] -40, bounds['ymin'] -40),\n",
        "            (bounds['xmax'] +40, bounds['ymin'] -40),\n",
        "            (bounds['xmax'] +40, bounds['ymax'] +40),\n",
        "            (bounds['xmin'] -40, bounds['ymax'] +40)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "cellView": "code",
        "id": "9P-lu1x4kEva"
      },
      "outputs": [],
      "source": [
        "class ObjectDetection:\n",
        "    def __init__(self, model, image_path):\n",
        "        self.model = model\n",
        "        self.image_path = image_path\n",
        "\n",
        "    def detect(self):\n",
        "        img = Image.open(self.image_path)\n",
        "        results = self.model(img)\n",
        "        return results\n",
        "\n",
        "\n",
        "class YOLOv5(ObjectDetection):\n",
        "    def detect(self):\n",
        "        results = super().detect()\n",
        "        filter = results.pandas().xyxy[0]\n",
        "        human_preds = filter[filter['name'] == 'person'].copy()\n",
        "        human_preds['name'] = ['person_' +\n",
        "                               str(index) for index in human_preds.index]\n",
        "        human_info = {\n",
        "            'predictions': [\n",
        "                {\n",
        "                    'label': row['name'],\n",
        "                    'vertices': convert_to_polygon({\n",
        "                        'xmin': row['xmin'], 'ymin': row['ymin'],\n",
        "                        'xmax': row['xmax'], 'ymax': row['ymax']\n",
        "                    })\n",
        "                } for _, row in human_preds.iterrows()\n",
        "            ]\n",
        "        }\n",
        "        return human_info\n",
        "\n",
        "class ImageAnnotatorClient(ObjectDetection):\n",
        "    def detect(self):\n",
        "        # Read the image file\n",
        "        with open(self.image_path, \"rb\") as image_file:\n",
        "            content = image_file.read()\n",
        "\n",
        "        # Convert the image content to a numpy array\n",
        "        nparr = np.frombuffer(content, np.uint8)\n",
        "        # Decode the numpy array to an image\n",
        "        img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Preprocess the image\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)\n",
        "        # Apply Gaussian Blur\n",
        "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # Convert the preprocessed image back to bytes\n",
        "        _, buffer = cv2.imencode('.jpg', blurred)\n",
        "        preprocessed_content = buffer.tobytes()\n",
        "\n",
        "        # Use the preprocessed image for text detection\n",
        "        image = vision.Image(content=preprocessed_content)\n",
        "        response = self.model.text_detection(image=image)\n",
        "\n",
        "        if hasattr(response, 'error') and response.error.message:\n",
        "            raise Exception(\n",
        "                f\"{response.error.message}\\nFor more info on error messages, check: https://cloud.google.com/apis/design/errors\")\n",
        "\n",
        "        texts = response.text_annotations\n",
        "        if not texts:\n",
        "            return \"No text detected\"\n",
        "\n",
        "        results = {\n",
        "            'image': {\n",
        "                'width': response.full_text_annotation.pages[0].width,\n",
        "                'height': response.full_text_annotation.pages[0].height,\n",
        "            },\n",
        "            'predictions': [\n",
        "                {\n",
        "                    'label': text.description,\n",
        "                    'vertices': [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
        "                } for text in texts\n",
        "            ]\n",
        "        }\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "UMZ0r2F5mONb"
      },
      "outputs": [],
      "source": [
        "image_path = 'Beer/48.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "FAtyVEGnYZ2s",
        "outputId": "967eb9fb-15e6-4038-b52d-589f9945b246"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\Thanh/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2024-6-28 Python-3.12.3 torch-2.3.1 CUDA:0 (NVIDIA GeForce MX230, 2048MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5n')\n",
        "human_detector = YOLOv5(model, image_path)\n",
        "human_info = human_detector.detect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>vertice_0</th>\n",
              "      <th>vertice_1</th>\n",
              "      <th>vertice_2</th>\n",
              "      <th>vertice_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>person_1</td>\n",
              "      <td>(31.625839233398438, 307.0141906738281)</td>\n",
              "      <td>(251.49461364746094, 307.0141906738281)</td>\n",
              "      <td>(251.49461364746094, 968.5150146484375)</td>\n",
              "      <td>(31.625839233398438, 968.5150146484375)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>person_2</td>\n",
              "      <td>(518.756591796875, 546.7799072265625)</td>\n",
              "      <td>(984.3592529296875, 546.7799072265625)</td>\n",
              "      <td>(984.3592529296875, 1299.0855712890625)</td>\n",
              "      <td>(518.756591796875, 1299.0855712890625)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>person_3</td>\n",
              "      <td>(136.74790954589844, 319.6841735839844)</td>\n",
              "      <td>(596.0384521484375, 319.6841735839844)</td>\n",
              "      <td>(596.0384521484375, 1061.3719482421875)</td>\n",
              "      <td>(136.74790954589844, 1061.3719482421875)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>person_11</td>\n",
              "      <td>(314.9019775390625, 357.0315856933594)</td>\n",
              "      <td>(555.3452758789062, 357.0315856933594)</td>\n",
              "      <td>(555.3452758789062, 672.1087646484375)</td>\n",
              "      <td>(314.9019775390625, 672.1087646484375)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                vertice_0  \\\n",
              "0   person_1  (31.625839233398438, 307.0141906738281)   \n",
              "1   person_2    (518.756591796875, 546.7799072265625)   \n",
              "2   person_3  (136.74790954589844, 319.6841735839844)   \n",
              "3  person_11   (314.9019775390625, 357.0315856933594)   \n",
              "\n",
              "                                 vertice_1  \\\n",
              "0  (251.49461364746094, 307.0141906738281)   \n",
              "1   (984.3592529296875, 546.7799072265625)   \n",
              "2   (596.0384521484375, 319.6841735839844)   \n",
              "3   (555.3452758789062, 357.0315856933594)   \n",
              "\n",
              "                                 vertice_2  \\\n",
              "0  (251.49461364746094, 968.5150146484375)   \n",
              "1  (984.3592529296875, 1299.0855712890625)   \n",
              "2  (596.0384521484375, 1061.3719482421875)   \n",
              "3   (555.3452758789062, 672.1087646484375)   \n",
              "\n",
              "                                  vertice_3  \n",
              "0   (31.625839233398438, 968.5150146484375)  \n",
              "1    (518.756591796875, 1299.0855712890625)  \n",
              "2  (136.74790954589844, 1061.3719482421875)  \n",
              "3    (314.9019775390625, 672.1087646484375)  "
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame([{\n",
        "    'label': pred['label'],\n",
        "    'vertice_0': pred['vertices'][0],\n",
        "    'vertice_1': pred['vertices'][1],\n",
        "    'vertice_2': pred['vertices'][2],\n",
        "    'vertice_3': pred['vertices'][3]\n",
        "} for pred in human_info['predictions']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "DxymvJABkOHe"
      },
      "outputs": [],
      "source": [
        "model = vision.ImageAnnotatorClient()\n",
        "text_detector = ImageAnnotatorClient(model, image_path)\n",
        "text_info = text_detector.detect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>vertice_0</th>\n",
              "      <th>vertice_1</th>\n",
              "      <th>vertice_2</th>\n",
              "      <th>vertice_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENT\\n10000\\nMar\\nJOUT AND\\nYAD\\n194\\nĐƯỜNG\\nSỐ 8</td>\n",
              "      <td>(44, 182)</td>\n",
              "      <td>(814, 182)</td>\n",
              "      <td>(814, 1020)</td>\n",
              "      <td>(44, 1020)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENT</td>\n",
              "      <td>(110, 1006)</td>\n",
              "      <td>(105, 949)</td>\n",
              "      <td>(126, 947)</td>\n",
              "      <td>(131, 1004)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000</td>\n",
              "      <td>(139, 1018)</td>\n",
              "      <td>(135, 953)</td>\n",
              "      <td>(152, 952)</td>\n",
              "      <td>(156, 1017)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mar</td>\n",
              "      <td>(44, 659)</td>\n",
              "      <td>(76, 647)</td>\n",
              "      <td>(81, 660)</td>\n",
              "      <td>(49, 672)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JOUT</td>\n",
              "      <td>(53, 403)</td>\n",
              "      <td>(89, 404)</td>\n",
              "      <td>(89, 416)</td>\n",
              "      <td>(53, 415)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              label    vertice_0   vertice_1  \\\n",
              "0  ENT\\n10000\\nMar\\nJOUT AND\\nYAD\\n194\\nĐƯỜNG\\nSỐ 8    (44, 182)  (814, 182)   \n",
              "1                                               ENT  (110, 1006)  (105, 949)   \n",
              "2                                             10000  (139, 1018)  (135, 953)   \n",
              "3                                               Mar    (44, 659)   (76, 647)   \n",
              "4                                              JOUT    (53, 403)   (89, 404)   \n",
              "\n",
              "     vertice_2    vertice_3  \n",
              "0  (814, 1020)   (44, 1020)  \n",
              "1   (126, 947)  (131, 1004)  \n",
              "2   (152, 952)  (156, 1017)  \n",
              "3    (81, 660)    (49, 672)  \n",
              "4    (89, 416)    (53, 415)  "
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame([{\n",
        "    'label': pred['label'],\n",
        "    'vertice_0': pred['vertices'][0],\n",
        "    'vertice_1': pred['vertices'][1],\n",
        "    'vertice_2': pred['vertices'][2],\n",
        "    'vertice_3': pred['vertices'][3]\n",
        "} for pred in text_info['predictions']]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "t1YTgnny5yW_"
      },
      "outputs": [],
      "source": [
        "CLIENT = InferenceHTTPClient(\n",
        "    api_url=\"https://detect.roboflow.com\",\n",
        "    api_key=\"myga9csfPR6CPfAMerk7\"\n",
        ")\n",
        "\n",
        "clothes_info = CLIENT.infer(image_path, model_id=\"clothing-exome/1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "5iuYUxwr6VBR"
      },
      "outputs": [],
      "source": [
        "def convert_bounding_box_to_polygon(detection_results):\n",
        "    \"\"\"\n",
        "    Converts bounding box center points to polygon vertices.\n",
        "\n",
        "    :param detection_results: Dictionary containing image info and predictions.\n",
        "    :return: Updated dictionary with predictions containing polygon vertices.\n",
        "    \"\"\"\n",
        "    polygon_info = {\n",
        "        'image': {\n",
        "            'width': detection_results['image']['width'],\n",
        "            'height': detection_results['image']['height']\n",
        "        },\n",
        "        'predictions': []\n",
        "    }\n",
        "\n",
        "    for prediction in detection_results['predictions']:\n",
        "        vertices = [\n",
        "            (prediction['x'] - prediction['width'] / 2,\n",
        "             prediction['y'] - prediction['height'] / 2),  # Top-left\n",
        "            (prediction['x'] + prediction['width'] / 2,\n",
        "             prediction['y'] - prediction['height'] / 2),  # Top-right\n",
        "            (prediction['x'] + prediction['width'] / 2,\n",
        "             prediction['y'] + prediction['height'] / 2),  # Bottom-right\n",
        "            (prediction['x'] - prediction['width'] / 2,\n",
        "             prediction['y'] + prediction['height'] / 2)   # Bottom-left\n",
        "        ]\n",
        "\n",
        "        polygon_info['predictions'].append({\n",
        "            'label': prediction['class'],\n",
        "            'vertices': vertices\n",
        "        })\n",
        "\n",
        "    return polygon_info\n",
        "\n",
        "\n",
        "# Example usage\n",
        "clothes_info = convert_bounding_box_to_polygon(clothes_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>vertice_0</th>\n",
              "      <th>vertice_1</th>\n",
              "      <th>vertice_2</th>\n",
              "      <th>vertice_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jacket</td>\n",
              "      <td>(168.75, 446.25)</td>\n",
              "      <td>(411.25, 446.25)</td>\n",
              "      <td>(411.25, 857.5)</td>\n",
              "      <td>(168.75, 857.5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>skirt</td>\n",
              "      <td>(733.75, 712.5)</td>\n",
              "      <td>(951.25, 712.5)</td>\n",
              "      <td>(951.25, 991.25)</td>\n",
              "      <td>(733.75, 991.25)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label         vertice_0         vertice_1         vertice_2  \\\n",
              "0  jacket  (168.75, 446.25)  (411.25, 446.25)   (411.25, 857.5)   \n",
              "1   skirt   (733.75, 712.5)   (951.25, 712.5)  (951.25, 991.25)   \n",
              "\n",
              "          vertice_3  \n",
              "0   (168.75, 857.5)  \n",
              "1  (733.75, 991.25)  "
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame([{\n",
        "    'label': pred['label'],\n",
        "    'vertice_0': pred['vertices'][0],\n",
        "    'vertice_1': pred['vertices'][1],\n",
        "    'vertice_2': pred['vertices'][2],\n",
        "    'vertice_3': pred['vertices'][3]\n",
        "} for pred in clothes_info['predictions']]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "dYF_p_mzfWt9"
      },
      "outputs": [],
      "source": [
        "all_pred = {'predictions': human_info['predictions'] + text_info['predictions'][1:]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "2qAc3tG4hKSI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved to Beer_with_bbox/48_Bbox.jpg\n"
          ]
        }
      ],
      "source": [
        "draw_bbox = DrawBoundingBoxes(Image.open(image_path), all_pred)\n",
        "draw_bbox.save_image_with_bbox('Beer_with_bbox/48_Bbox.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "SAjoICwbvd2l"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "    text = text.replace('•', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_image_information(image_path, human_detector, text_detector, clothes_detector):\n",
        "    image = Image.open(image_path)\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following image information and provide detailed insights based on the criteria given below:\n",
        "\n",
        "    Human Detection Results:\n",
        "    {human_detector}\n",
        "\n",
        "    Text Detection Results:\n",
        "    {text_detector}\n",
        "\n",
        "\n",
        "    Business Problem 1: How many people handling a can of beer or a bottle of beer?\n",
        "    - Specifically, count the number of people drinking Heineken beer in the restaurant.\n",
        "\n",
        "    Business Problem 4: Tracking marketing staff\n",
        "    - Identify any marketing staff present in the image based on their clothing.\n",
        "    - Confirm if there are at least two marketing staff members at each restaurant location.\n",
        "\n",
        "    Insights:\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = model.generate_content([prompt, image], stream=True)\n",
        "    response.resolve()\n",
        "    return to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "xrQBfMKF1nTR"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> ## Insights:\n",
              "> \n",
              "> **Business Problem 1:**\n",
              "> \n",
              "> * **Analysis:** Based on the provided information, it is impossible to determine the brand of beer being consumed. The image does not show any Heineken branding. There is one person holding a can of beer (person_2) and another person holding a bottle (likely beer) (person_3). \n",
              "> * **Answer:** We cannot determine if the beer is Heineken, but there are **two** people handling beer (one holding a can and one holding a bottle).\n",
              "> \n",
              "> **Business Problem 4:**\n",
              "> \n",
              "> * **Analysis:** The provided information only identifies people by their position in the image, but does not describe clothing. This makes it impossible to identify any marketing staff members based on their clothing.\n",
              "> * **Answer:** We cannot confirm if there are any marketing staff members present in the image. There is insufficient information to answer this question.\n",
              "> \n",
              "> **Overall:** The provided data is not sufficient to answer the business problems in detail. While we can identify some people handling beer, we lack information about the specific brand of beer and the clothing worn by the people in the image.  Further information is needed about the objects in the image and the clothing of the people to accurately analyze and answer the business problems.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyze_image_information(image_path, human_info, text_info, clothes_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> ## Promotional Materials Analysis:\n",
              "> \n",
              "> **Promotional materials with Heineken logo:**\n",
              "> \n",
              "> 1. **Poster:** Large poster displaying Heineken logo and slogan, \"Vui tiec thoai mai\" (Enjoy your party) with an image of Heineken cans. \n",
              "> 2. **Beer Boxes:** Multiple boxes with the Heineken logo are stacked against the wall.  \n",
              "> 3. **Can:** Visible on the poster. \n",
              "> \n",
              "> **Classification and count:**\n",
              "> \n",
              "> - **Poster:** 1\n",
              "> - **Beer Boxes:** 11\n",
              "> - **Can:** 1\n",
              "> \n",
              "> **Setting:**\n",
              "> \n",
              "> The setting appears to be a **restaurant** or an **event location** based on the presence of tables, chairs, and beer boxes.\n",
              "> \n",
              "> **Competitor logos:**\n",
              "> \n",
              "> The image shows a **Tiger Crystal** logo, indicating a competitor brand is present. \n",
              "> \n",
              "> **Insights:**\n",
              "> \n",
              "> - Heineken is actively promoting its brand within this restaurant or event location.\n",
              "> - The presence of competitor logos suggests potential competition in the market. \n",
              "> - The volume of Heineken beer boxes indicates a significant presence and potentially popular choice at this establishment.\n",
              "> - The poster and slogan aim to encourage customers to enjoy their event with Heineken."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_path = 'Beer/76.jpg'\n",
        "model = vision.ImageAnnotatorClient()\n",
        "text_detector = ImageAnnotatorClient(model, image_path)\n",
        "text_info = text_detector.detect()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Analyze the provided image from a restaurant or event location to identify visible promotional materials featuring the Heineken logo. Classify each item into categories: ice bucket, bottle, can, refrigerator, signboard, poster, display counter, display table, and umbrella. Pay special attention to counting beer boxes.\n",
        "\n",
        "Text Detection Insights:\n",
        "{text_info[1:]}\n",
        "\n",
        "Required Information:\n",
        "- Enumerate promotional materials with the Heineken logo.\n",
        "- Classify each material and count beer boxes.\n",
        "\n",
        "Context and Competitor Analysis:\n",
        "- Determine the setting: restaurant, supermarket, or store.\n",
        "- Identify competitor logos present.\n",
        "\n",
        "Insights:\n",
        "\"\"\"\n",
        "from PIL import ImageOps\n",
        "image = Image.open(image_path)\n",
        "image = ImageOps.exif_transpose(image)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([prompt, image], stream=True)\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': {'width': 600, 'height': 800},\n",
              " 'predictions': [{'label': 'P\\nLARUE\\nLARUE\\n1\\nnabati\\nNurów\\nMu\\nLARUE\\nSPECIAL\\nCOOLPACK\\nHeineken UE\\nTiger\\nLARUE\\n2024\\n241\\nHeineken\\n2024\\nHeineken\\nLARUE\\nHeineken\\n-SMOOTH-\\nHekel\\nHeineken\\nCHITMAN\\nSHUNG\\n22-2\\n24\\n2924\\nCOTHAN\\nHeineken\\nTHUNG\\n77-7\\nHeineken\\nTiger\\nMAN\\n14040\\n2232\\n24\\nHeineken\\n2\\n24\\nHeineken\\nTiger\\nCOLY\\nTiger\\nHeineken\\nTiger\\nTiger\\n24☆\\nBIVINA\\nHeineken\\nTifer\\nEXPORT',\n",
              "   'vertices': [(0, 38), (599, 38), (599, 725), (0, 725)]},\n",
              "  {'label': 'P', 'vertices': [(0, 408), (7, 404), (12, 419), (0, 423)]},\n",
              "  {'label': 'LARUE', 'vertices': [(18, 79), (62, 68), (65, 81), (21, 92)]},\n",
              "  {'label': 'LARUE', 'vertices': [(16, 226), (51, 213), (55, 224), (20, 237)]},\n",
              "  {'label': '1', 'vertices': [(37, 537), (46, 534), (52, 549), (42, 552)]},\n",
              "  {'label': 'nabati',\n",
              "   'vertices': [(152, 265), (191, 261), (193, 277), (154, 281)]},\n",
              "  {'label': 'Nurów', 'vertices': [(294, 43), (304, 80), (295, 82), (284, 46)]},\n",
              "  {'label': 'Mu', 'vertices': [(314, 47), (321, 73), (310, 76), (302, 50)]},\n",
              "  {'label': 'LARUE',\n",
              "   'vertices': [(442, 135), (513, 124), (516, 142), (445, 154)]},\n",
              "  {'label': 'SPECIAL',\n",
              "   'vertices': [(464, 170), (504, 164), (505, 176), (466, 182)]},\n",
              "  {'label': 'COOLPACK',\n",
              "   'vertices': [(414, 223), (472, 214), (475, 233), (417, 242)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(361, 254), (482, 244), (484, 268), (363, 279)]},\n",
              "  {'label': 'UE',\n",
              "   'vertices': [(501, 242), (532, 239), (534, 263), (503, 266)]},\n",
              "  {'label': 'Tiger', 'vertices': [(524, 74), (572, 62), (578, 83), (529, 95)]},\n",
              "  {'label': 'LARUE', 'vertices': [(53, 334), (83, 316), (88, 325), (58, 343)]},\n",
              "  {'label': '2024',\n",
              "   'vertices': [(150, 325), (189, 324), (189, 337), (150, 338)]},\n",
              "  {'label': '241',\n",
              "   'vertices': [(238, 325), (256, 323), (257, 334), (239, 336)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(161, 354), (266, 346), (267, 366), (163, 374)]},\n",
              "  {'label': '2024',\n",
              "   'vertices': [(170, 397), (204, 397), (204, 408), (170, 408)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(180, 420), (279, 419), (279, 436), (180, 437)]},\n",
              "  {'label': 'LARUE',\n",
              "   'vertices': [(312, 330), (377, 311), (382, 329), (317, 347)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(505, 280), (478, 345), (453, 334), (480, 270)]},\n",
              "  {'label': '-SMOOTH-',\n",
              "   'vertices': [(311, 373), (397, 351), (401, 365), (315, 388)]},\n",
              "  {'label': 'Hekel',\n",
              "   'vertices': [(478, 364), (534, 362), (535, 378), (479, 380)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(463, 389), (588, 385), (588, 404), (464, 408)]},\n",
              "  {'label': 'CHITMAN',\n",
              "   'vertices': [(309, 411), (343, 409), (344, 419), (310, 421)]},\n",
              "  {'label': 'SHUNG',\n",
              "   'vertices': [(314, 429), (346, 429), (346, 440), (314, 440)]},\n",
              "  {'label': '22-2',\n",
              "   'vertices': [(320, 442), (346, 442), (346, 450), (320, 450)]},\n",
              "  {'label': '24',\n",
              "   'vertices': [(468, 441), (486, 441), (486, 453), (468, 453)]},\n",
              "  {'label': '2924',\n",
              "   'vertices': [(194, 464), (230, 464), (230, 475), (194, 475)]},\n",
              "  {'label': 'COTHAN',\n",
              "   'vertices': [(321, 465), (356, 466), (356, 475), (321, 474)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(204, 486), (300, 486), (300, 501), (204, 501)]},\n",
              "  {'label': 'THUNG',\n",
              "   'vertices': [(327, 482), (362, 483), (362, 493), (327, 492)]},\n",
              "  {'label': '77-7',\n",
              "   'vertices': [(333, 494), (359, 495), (359, 503), (333, 502)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(463, 476), (599, 473), (599, 493), (463, 496)]},\n",
              "  {'label': 'Tiger',\n",
              "   'vertices': [(271, 542), (312, 544), (311, 559), (270, 557)]},\n",
              "  {'label': 'MAN',\n",
              "   'vertices': [(343, 519), (358, 519), (358, 524), (343, 524)]},\n",
              "  {'label': '14040',\n",
              "   'vertices': [(332, 533), (362, 533), (362, 542), (332, 542)]},\n",
              "  {'label': '2232',\n",
              "   'vertices': [(336, 543), (362, 543), (362, 550), (336, 550)]},\n",
              "  {'label': '24',\n",
              "   'vertices': [(469, 509), (489, 509), (489, 523), (469, 523)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(470, 539), (596, 542), (596, 561), (470, 558)]},\n",
              "  {'label': '2', 'vertices': [(416, 568), (441, 567), (441, 580), (416, 581)]},\n",
              "  {'label': '24',\n",
              "   'vertices': [(470, 564), (495, 566), (494, 582), (469, 580)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(474, 593), (591, 601), (590, 618), (473, 610)]},\n",
              "  {'label': 'Tiger',\n",
              "   'vertices': [(289, 600), (327, 602), (326, 615), (288, 613)]},\n",
              "  {'label': 'COLY',\n",
              "   'vertices': [(350, 604), (383, 604), (383, 615), (350, 615)]},\n",
              "  {'label': 'Tiger',\n",
              "   'vertices': [(417, 625), (454, 628), (453, 640), (416, 637)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(481, 645), (593, 659), (591, 674), (479, 660)]},\n",
              "  {'label': 'Tiger',\n",
              "   'vertices': [(298, 649), (335, 654), (333, 667), (296, 662)]},\n",
              "  {'label': 'Tiger',\n",
              "   'vertices': [(425, 663), (460, 666), (459, 677), (424, 674)]},\n",
              "  {'label': '24',\n",
              "   'vertices': [(486, 669), (504, 671), (501, 693), (483, 691)]},\n",
              "  {'label': '☆', 'vertices': [(518, 673), (559, 678), (556, 699), (515, 694)]},\n",
              "  {'label': 'BIVINA',\n",
              "   'vertices': [(375, 680), (460, 691), (458, 705), (373, 694)]},\n",
              "  {'label': 'Heineken',\n",
              "   'vertices': [(485, 696), (593, 711), (591, 725), (483, 710)]},\n",
              "  {'label': 'Tifer',\n",
              "   'vertices': [(307, 698), (342, 703), (340, 714), (305, 709)]},\n",
              "  {'label': 'EXPORT',\n",
              "   'vertices': [(400, 705), (445, 712), (444, 719), (399, 712)]}]}"
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved to Beer_with_bbox/76_Bbox.jpg\n"
          ]
        }
      ],
      "source": [
        "draw_bbox = DrawBoundingBoxes(image, text_info)\n",
        "draw_bbox.save_image_with_bbox('Beer_with_bbox/76_Bbox.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q32W4ZPj-GsO"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "\n",
        "def download_video_from_youtube(link, path):\n",
        "    yt = YouTube(link)\n",
        "    video = yt.streams.get_highest_resolution()\n",
        "\n",
        "    # download the video\n",
        "    video.download(path)\n",
        "\n",
        "# example usage:\n",
        "download_video_from_youtube('https://youtu.be/0kSy34bXOsQ?si=VSKRj83xrqbWiusr', 'videos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1CVdJgX9C_7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in geeksforgeeks.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        }
      ],
      "source": [
        "import moviepy.editor as mp\n",
        "import speech_recognition as sr\n",
        "\n",
        "# Load the video\n",
        "video = mp.VideoFileClip(\n",
        "    \"videos/Introducing Heineken 00 on Draught - Denise Van Outen.mp4\")\n",
        "\n",
        "# Extract the audio from the video\n",
        "audio_file = video.audio\n",
        "audio_file.write_audiofile(\"geeksforgeeks.wav\")\n",
        "\n",
        "# Initialize recognizer\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# Load the audio file\n",
        "with sr.AudioFile(\"geeksforgeeks.wav\") as source:\n",
        "    data = r.record(source)\n",
        "\n",
        "# Convert speech to text\n",
        "text = r.recognize_google(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzPRfyZZ-4rW"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> I think alcohol-free drinks should be more readily available then they already are and this is why you know for me being able to come to a pub and have Heineken 00 draft is just an absolute godsend for me because you don't always want to turn up a problem be nursing a cola or eliminate join me and you want to feel part of the team and I am a team player I don't want to be excluded now I feel like alcohol for me is something that I pick and choose whenever I feel it's the right time to have a drink so I'm definitely one of those moderate drinkers I don't I don't go out now to get drunk I think when I was young girl with the purpose of just getting really drunk but now when I go out I want to have good conversation I want to remember it the next day I think the music conception about alcoholic drink up is the first of all you must have an issue with alcohol and not everybody has and possibly are you pregnant which again you know we shouldn't have to keep defending ourselves and you know I found myself in the past when I've chosen not to drink and I've gone now with friends that I've even made up excuses because it's actually easier to say oh I'm on antibiotics I can't drink and actually just say don't fancy drinking today I'm really excited about how the Great British pub is changing because I feel like it's open its doors to everybody now you can all go and feel comfortable and that for me is a brilliant thing because you know with everything that's gone on over the last year and a half and everything's been closed down it's nice to have somewhere that comes like a Social Hub that you can all go to and all feel comfortable people from all walks of life all ages and it's catering for everybody finally I can stand at the bar I don't have to say I'm on antibiotics no I'm not pregnant I can order my draft zero zero and just enjoy it and be the magic that I used to be but grown up one"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elc9yw6f_w38"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> Here are the answers to your questions:\n",
              "> \n",
              "> 1. **Heineken 0.0** is the beer mentioned in the passage.\n",
              "> 2. **Heineken 0.0** is the beer being described in detail. The passage specifically highlights how the availability of this alcohol-free beer is a \"godsend\" for the speaker and how it allows them to feel included and part of the group when socializing at a pub. \n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating the prompt for the Gemini API\n",
        "prompt = f\"Given the following passage: '{\n",
        "    text}', answer the following questions: \\n1. Which beer is mentioned in the passage? \\n2. Which beer is being described in detail?\"\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(prompt, stream=True)\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = 'Beer/48.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "from inference_sdk import InferenceHTTPClient\n",
        "\n",
        "CLIENT = InferenceHTTPClient(\n",
        "    api_url=\"https://detect.roboflow.com\",\n",
        "    api_key=\"myga9csfPR6CPfAMerk7\"\n",
        ")\n",
        "\n",
        "result = CLIENT.infer(image_path, model_id=\"gianamkhanh/3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_info = convert_bounding_box_to_polygon(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved to Beer_with_bbox/1387_Bbox.jpg\n"
          ]
        }
      ],
      "source": [
        "draw_bbox = DrawBoundingBoxes(Image.open(image_path), result_info)\n",
        "draw_bbox.save_image_with_bbox('Beer_with_bbox/1387_Bbox.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': {'width': 960, 'height': 1280},\n",
              " 'predictions': [{'label': 'person',\n",
              "   'vertices': [(568.75, 581.25),\n",
              "    (936.25, 581.25),\n",
              "    (936.25, 1277.5),\n",
              "    (568.75, 1277.5)]},\n",
              "  {'label': 'biaviet-prometer',\n",
              "   'vertices': [(75.0, 348.75),\n",
              "    (217.5, 348.75),\n",
              "    (217.5, 948.75),\n",
              "    (75.0, 948.75)]},\n",
              "  {'label': 'person',\n",
              "   'vertices': [(187.5, 351.25),\n",
              "    (560.0, 351.25),\n",
              "    (560.0, 1018.75),\n",
              "    (187.5, 1018.75)]},\n",
              "  {'label': 'biaviet-prometer',\n",
              "   'vertices': [(368.75, 398.75),\n",
              "    (555.0, 398.75),\n",
              "    (555.0, 610.0),\n",
              "    (368.75, 610.0)]},\n",
              "  {'label': 'biaviet-can',\n",
              "   'vertices': [(565.0, 660.0),\n",
              "    (601.25, 660.0),\n",
              "    (601.25, 721.25),\n",
              "    (565.0, 721.25)]},\n",
              "  {'label': 'biaviet-brand',\n",
              "   'vertices': [(520.0, 440.0),\n",
              "    (555.0, 440.0),\n",
              "    (555.0, 492.5),\n",
              "    (520.0, 492.5)]},\n",
              "  {'label': 'biaviet-brand',\n",
              "   'vertices': [(521.25, 500.0),\n",
              "    (557.5, 500.0),\n",
              "    (557.5, 616.25),\n",
              "    (521.25, 616.25)]},\n",
              "  {'label': 'biaviet-can',\n",
              "   'vertices': [(533.75, 653.75),\n",
              "    (571.25, 653.75),\n",
              "    (571.25, 710.0),\n",
              "    (533.75, 710.0)]}]}"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_image_information_general(image_path, object_detector):\n",
        "    image = Image.open(image_path)\n",
        "    prompt = f\"\"\"\n",
        "    Given the object detection results below, provide insights based on the following criteria:\n",
        "\n",
        "    Object Detection Results:\n",
        "    {object_detector}\n",
        "\n",
        "    Criteria for Analysis:\n",
        "    1. A person is considered to be holding a \"beer-can\" if a 'beer-can' object is detected within a close proximity to the 'person' object, specifically if any part of the 'beer-can' is within the bounding box of the 'person'.\n",
        "    2. Marketing staff are identified by the presence of 'promotional-material' objects. A marketing staff member must be in close proximity to the 'promotional-material', similar to the criteria for holding a 'beer-can'.\n",
        "    3. For a location to be considered as having sufficient marketing staff presence, at least two individuals meeting the marketing staff criteria must be detected.\n",
        "\n",
        "    Please analyze the object detection results and provide:\n",
        "    - The number of people holding a \"beer-can\".\n",
        "    - Whether there are at least two marketing staff members at the location, based on the criteria above.\n",
        "\n",
        "    Insights:\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = model.generate_content([prompt, image], stream=True)\n",
        "    response.resolve()\n",
        "    return to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> ## Insights:\n",
              "> \n",
              "> **Business Problem 1:**\n",
              "> \n",
              "> - There is **one** person holding a \"biaviet-can\" in their hand. \n",
              "> - This can be identified by looking at the object detection result: `{'label': 'biaviet-can', 'vertices': [(565.0, 660.0), (601.25, 660.0), (601.25, 721.25), (565.0, 721.25)]}`. \n",
              "> - The person holding the can is the one in the blue shirt, standing next to the table.\n",
              "> \n",
              "> **Business Problem 4:**\n",
              "> \n",
              "> - **Two** people can be identified as marketing staff:\n",
              ">     - The person holding a \"biaviet-can\" in their hand (mentioned above). \n",
              ">     - The person holding a \"biaviet-prometer\" (identified by the bounding box: `{'label': 'biaviet-prometer', 'vertices': [(75.0, 348.75), (217.5, 348.75), (217.5, 948.75), (75.0, 948.75)]}`).\n",
              "> - The image appears to show **one** restaurant location.\n",
              "> - There are **at least two** marketing staff members at this location, fulfilling the requirement.\n",
              "> \n",
              "> **Additional Notes:**\n",
              "> \n",
              "> - The object detection model seems to have correctly identified most objects, including people and \"biaviet\" products.\n",
              "> - The image provides valuable information for analyzing marketing efforts and staff presence at a specific restaurant location.\n",
              "> \n",
              "> **Recommendations:**\n",
              "> \n",
              "> - It's beneficial to investigate the \"biaviet-brand\" bounding boxes. Are they correctly identified? What do these brands represent?\n",
              "> - It would be helpful to gather more images from different restaurant locations to verify the presence of marketing staff and obtain a comprehensive view of their deployment.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyze_image_information(image_path, result_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = [\n",
        "  {\"xmin\": 527, \"ymin\": 239, \"xmax\": 584, \"ymax\": 392, \"class\": \"tiger-banner\"},\n",
        "  {\"xmin\": 139, \"ymin\": 49, \"xmax\": 493, \"ymax\": 167, \"class\": \"tiger-banner\"},\n",
        "  {\"xmin\": 221, \"ymin\": 430, \"xmax\": 247, \"ymax\": 467, \"class\": \"tiger-poster\"},\n",
        "  {\"xmin\": 533, \"ymin\": 442, \"xmax\": 565, \"ymax\": 520, \"class\": \"tiger-poster\"}\n",
        "]\n",
        "\n",
        "image_path = 'Beer/5.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((640, 640))\n",
        "image.save('Beer/5_resized.jpg')\n",
        "draw = ImageDraw.Draw(image)\n",
        "for pred in preds:\n",
        "    draw.rectangle([(pred['xmin'], pred['ymin']),\n",
        "                   (pred['xmax'], pred['ymax'])], outline='red', width=2)\n",
        "    draw.text((pred['xmin'], pred['ymin']), pred['class'], fill='red')\n",
        "\n",
        "image.save('Beer_with_bbox/5_Bbox.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'xmin': 527, 'ymin': 239, 'xmax': 584, 'ymax': 392, 'class': 'tiger-brand'},\n",
              " {'xmin': 139, 'ymin': 49, 'xmax': 493, 'ymax': 167, 'class': 'tiger-brand'},\n",
              " {'xmin': 221, 'ymin': 430, 'xmax': 247, 'ymax': 467, 'class': 'tiger-brand'},\n",
              " {'xmin': 533, 'ymin': 442, 'xmax': 565, 'ymax': 520, 'class': 'tiger-brand'}]"
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_preds = []\n",
        "for pred in preds:\n",
        "    if pred['class'] == 'tiger-brand':\n",
        "        n_preds.append(pred)\n",
        "n_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> ```json\n",
              "> {preds}\n",
              "> ```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Given the bounding box predictions for an image, refine the classifications for boxes with the class ending in '-brand', ensuring to maintain the original bounding box coordinates. The goal is to provide more accurate and detailed classifications for these specific boxes without altering their positions or sizes. For each bounding box with a class ending in '-brand', analyze the image content within the bounding box to determine a more specific and accurate class. Possible refined classes include 'tiger-logo', 'competitor-logo', 'tiger-text', or 'other-brand'.\n",
        "\n",
        "Bounding Box Predictions:\n",
        "{preds}\n",
        "\n",
        "Tasks:\n",
        "1. For each bounding box with a class ending in '-brand', provide a refined classification based on the content within the bounding box. Maintain the original bounding box coordinates.\n",
        "2. Return the list of bounding boxes with updated classes for those previously labeled with '-brand', including their unchanged coordinates.\n",
        "\n",
        "Refined Bounding Box Predictions with Original Coordinates:\n",
        "\"\"\"\n",
        "\n",
        "image_path = 'Beer/5.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((640, 640))\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([prompt, image], stream=True)\n",
        "response.resolve()\n",
        "to_markdown(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
